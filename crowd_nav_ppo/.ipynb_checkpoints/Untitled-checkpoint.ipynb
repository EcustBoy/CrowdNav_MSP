{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from crowd_sim.envs.utils.action import ActionRot\n",
    "from env_setup import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Module\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.optim import Adam\n",
    "import math \n",
    "import random\n",
    "from torch.nn.functional import mse_loss\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "from torch.distributions import Categorical\n",
    "from multiprocessing_env import SubprocVecEnv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reward_counter() :\n",
    "    def __init__(self, n_workers) :\n",
    "        self.n_workers = n_workers\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self) :\n",
    "        self.reward_log = [[] for i in range(self.n_workers)]\n",
    "        self.acc_reward = np.zeros(self.n_workers)\n",
    "        self.acc_dones = np.zeros(self.n_workers)\n",
    "        \n",
    "    def update(self, rewards, dones) :\n",
    "        for i, (r, done) in enumerate(zip(rewards, dones)) :\n",
    "            self.update_worker(i, r, done)\n",
    "            \n",
    "    def update_worker(self, i, reward, done) :\n",
    "        self.acc_reward[i] += reward\n",
    "        if done : \n",
    "            self.reward_log[i].append(self.acc_reward[i])\n",
    "            self.acc_reward[i] = 0\n",
    "            self.acc_dones[i] += 1\n",
    "        \n",
    "    def plot_results(self, conv=100) :\n",
    "        plt.title('Reward avg per workers over episodes')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Reward avg')\n",
    "        for i in range(self.n_workers) :\n",
    "            rew_worker = rewards_avg = np.convolve(self.reward_log[i], np.ones((conv,))/conv, mode='valid')\n",
    "            plt.plot(rew_worker, label=f'worker {i}')\n",
    "        plt.show()\n",
    "        for i in range(self.n_workers) :\n",
    "            print('Worker {} did {} full sims'.format(i, self.acc_dones[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(advantage, ob_states, actions, log_probs, returns, n_steps, batch_size=4) :\n",
    "    for i in range(n_steps // batch_size) :\n",
    "        idxs = np.random.permutation(range(n_steps))[:batch_size]\n",
    "        yield advantage[idxs], ob_states[idxs], actions[idxs], log_probs[idxs], returns[idxs], idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_train(actor_critic, enviorements, n_workers, n_episodes = 100, lr = 1e-3, \n",
    "              gamma = 0.99, n_steps = 16, eps = 0.25, batch_size = 4, n_epochs = 2,\n",
    "              reward_counter=None, show_result=10, device='cpu', n_humans=5, st_size=14, print_time=False) :\n",
    "    \n",
    "    opt = Adam(actor_critic.model.parameters(), lr=lr)\n",
    "    reward_counter = Reward_counter(n_workers) if reward_counter is None else reward_counter\n",
    "    \n",
    "    for i in tqdm_notebook(range(n_episodes)) :\n",
    "\n",
    "        rewards = torch.zeros((n_steps, n_workers), dtype=torch.float).to(device)\n",
    "        mask = torch.zeros((n_steps, n_workers), dtype=torch.float).to(device)\n",
    "        log_probs = torch.zeros((n_steps, n_workers), dtype=torch.float).to(device)\n",
    "        values = torch.zeros((n_steps, n_workers), dtype=torch.float).to(device)\n",
    "        actions = torch.zeros((n_steps, n_workers), dtype=torch.float).to(device)\n",
    "        ob_states = torch.zeros((n_steps, n_workers, n_humans, st_size), dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "        if i == 0 :\n",
    "            observations = enviorements.reset()\n",
    "\n",
    "        step = 0\n",
    "        if print_time :\n",
    "            print('Starting episode {}'.format(i))\n",
    "        time_start_ep = time.time() \n",
    "        while step < n_steps :\n",
    "\n",
    "            vals, dist = actor_critic.predict(observations)\n",
    "            \n",
    "            ob_states[step] = torch.tensor(observations, dtype=torch.float32, device=device)\n",
    "            values[step] = vals.view(-1)\n",
    "\n",
    "            #choose action\n",
    "            act = dist.sample()\n",
    "            log_probs[step] = dist.log_prob(act)\n",
    "            actions[step] = act\n",
    "            \n",
    "            angle = act * 2 * math.pi/30\n",
    "            action = [ActionRot(1, angle[i]) for i in range(n_workers)]\n",
    "\n",
    "            obs, r, dones, _ = enviorements.step(action)\n",
    "            mask[step] = torch.tensor(1-dones).to(device)\n",
    "            rewards[step] = torch.from_numpy(r)\n",
    "\n",
    "            observations = obs\n",
    "\n",
    "            reward_counter.update(r, dones)\n",
    "            step+=1      \n",
    "        time_end_simu = time.time()\n",
    "\n",
    "        #discounted returns calculation (with bootstraping)\n",
    "        returns = torch.zeros((n_steps, n_workers), dtype=torch.float).to(device)\n",
    "        with torch.no_grad() :\n",
    "            q_val, _= actor_critic.predict(observations)\n",
    "        q_val = q_val.view(-1).detach()\n",
    "        for i in reversed(range(n_steps)) :\n",
    "            q_val = rewards[i] + gamma * q_val * (mask[i])\n",
    "            returns[i] = q_val\n",
    "        advantage = (returns - values).detach()\n",
    "        \n",
    "        time_start_opt = time.time()\n",
    "        #optimization\n",
    "        for epoch in range(n_epochs) :\n",
    "            a = 0\n",
    "            for adv_b, state_b, action_b, l_probs_b, returns_b, idxs in batch_iter(advantage, ob_states, actions, \n",
    "                                                                                   log_probs, returns.detach(), n_steps=n_steps, batch_size=batch_size) :\n",
    "\n",
    "                #vals, dist = actor_critic.predict(state_b.view(-1, n_humans, st_size).numpy())\n",
    "                vals, dist = actor_critic.predict(state_b.numpy())\n",
    "                \n",
    "                new_actor_probs = dist.log_prob(action_b)\n",
    "                \n",
    "                entropy = dist.entropy().mean()\n",
    "                \n",
    "                #probability ration and clipped prob ration\n",
    "                r = torch.exp((new_actor_probs) - (l_probs_b.detach()))\n",
    "                clipped_r = torch.clamp(r, 1-eps, 1+eps)\n",
    "                adv = returns_b.view(batch_size, n_workers, -1) - vals.view(batch_size, n_workers, 1)\n",
    "\n",
    "                #critic loss\n",
    "                critic_loss = adv.pow(2).mean()\n",
    "\n",
    "                #actor loss\n",
    "                clipped_loss = clipped_r * adv_b.detach()\n",
    "                loss_ = r * adv_b.detach()\n",
    "                actor_loss = -torch.min(clipped_loss, loss_).mean()\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss = 0.5 * (critic_loss + actor_loss) \n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        \n",
    "        time_end_ep = time.time()\n",
    "        time_epiode = time_end_ep - time_start_ep\n",
    "        time_opti = time_end_ep - time_start_opt\n",
    "        time_simu = time_end_simu - time_start_ep\n",
    "        \n",
    "        if print_time :\n",
    "            print('Episode {} took {:.2f}s, {:.2f}s simu, {:.2f}s opti'.format(i, time_epiode, time_simu, time_opti))\n",
    "        \n",
    "    if show_result is not None :\n",
    "        reward_counter.plot_results(conv=show_result)\n",
    "        \n",
    "    return actor_critic, reward_counter\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_policy = gen_policy_discrete()\n",
    "envs = gen_multi_envs(4, ac_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1878a45cfc840c1b8984c5485b89305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (16) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6388be46a490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mac_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshow_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-a1e587e98c8e>\u001b[0m in \u001b[0;36mppo_train\u001b[0;34m(actor_critic, enviorements, n_workers, n_episodes, lr, gamma, n_steps, eps, batch_size, n_epochs, reward_counter, show_result, device, n_humans, st_size, print_time)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_humans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mnew_actor_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zarr/lib/python3.7/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_pmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zarr/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (16) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "ac_policy, rc = ppo_train(ac_policy, envs, 4, n_episodes=100 , show_result=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/louis/anaconda3/envs/zarr/lib/python3.7/site-packages/torch/functional.py\u001b[0m(62)\u001b[0;36mbroadcast_tensors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     60 \u001b[0;31m                [0, 1, 2]])\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m    \"\"\"\n",
      "\u001b[0m\u001b[0;32m---> 62 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> UP\n",
      "*** NameError: name 'UP' is not defined\n",
      "ipdb> UP\n",
      "*** NameError: name 'UP' is not defined\n",
      "ipdb> up\n",
      "> \u001b[0;32m/home/louis/anaconda3/envs/zarr/lib/python3.7/site-packages/torch/distributions/categorical.py\u001b[0m(117)\u001b[0;36mlog_prob\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    115 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    116 \u001b[0;31m        \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 117 \u001b[0;31m        \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m        \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    119 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mlog_pmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> up\n",
      "> \u001b[0;32m<ipython-input-34-a1e587e98c8e>\u001b[0m(69)\u001b[0;36mppo_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m                \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_humans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m                \u001b[0mnew_actor_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m                \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m<ipython-input-36-6388be46a490>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mac_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshow_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "*** Oldest frame\n",
      "ipdb> down\n",
      "> \u001b[0;32m<ipython-input-34-a1e587e98c8e>\u001b[0m(69)\u001b[0;36mppo_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m                \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_humans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m                \u001b[0mnew_actor_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m                \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> state_b.shape\n",
      "torch.Size([4, 4, 5, 14])\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.Linear(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.6484e-01,  5.5036e-01],\n",
       "         [-4.2371e-02,  1.3881e-01],\n",
       "         [ 7.0237e-05,  1.1711e-01],\n",
       "         [-2.4346e-01,  1.0423e-01],\n",
       "         [-3.1349e-01,  8.4003e-01]],\n",
       "\n",
       "        [[-2.6750e-01,  6.9114e-01],\n",
       "         [-9.1891e-03,  2.3918e-02],\n",
       "         [-2.5294e-01,  5.9097e-01],\n",
       "         [-4.7895e-01,  1.3668e+00],\n",
       "         [-1.3171e-02,  5.2474e-01]],\n",
       "\n",
       "        [[ 1.2104e-01, -6.7630e-01],\n",
       "         [-2.8860e-01,  9.3269e-01],\n",
       "         [ 3.2791e-01, -3.8415e-01],\n",
       "         [-1.3280e-01,  1.4853e-01],\n",
       "         [-2.1250e-01,  5.5291e-01]],\n",
       "\n",
       "        [[-5.1835e-02,  8.8525e-01],\n",
       "         [-1.7309e-01,  4.3186e-02],\n",
       "         [ 3.5433e-01, -8.1039e-01],\n",
       "         [ 1.5923e-01,  4.2869e-01],\n",
       "         [-2.1285e-01, -1.2054e-01]],\n",
       "\n",
       "        [[-2.5951e-01,  7.5559e-01],\n",
       "         [ 9.8576e-02, -7.6201e-01],\n",
       "         [-7.5029e-02,  5.4759e-01],\n",
       "         [ 1.0404e-01, -1.3229e-01],\n",
       "         [ 9.3082e-03,  2.3355e-01]],\n",
       "\n",
       "        [[-4.7663e-02,  1.1104e-02],\n",
       "         [-5.0504e-01,  5.6975e-01],\n",
       "         [ 8.9307e-02,  7.8908e-02],\n",
       "         [-9.1509e-02,  1.0988e-01],\n",
       "         [-5.9157e-02,  5.8208e-01]],\n",
       "\n",
       "        [[-3.4820e-01,  3.8402e-01],\n",
       "         [ 8.2958e-03,  4.1321e-02],\n",
       "         [-1.0357e-01,  7.2379e-01],\n",
       "         [ 2.4152e-01,  4.2175e-01],\n",
       "         [-1.5814e-01,  5.7246e-01]],\n",
       "\n",
       "        [[-1.5641e-01,  8.2691e-01],\n",
       "         [-6.4414e-01,  1.2878e+00],\n",
       "         [-2.0607e-01,  1.7848e-01],\n",
       "         [-3.8439e-02,  1.0850e-01],\n",
       "         [-4.6606e-01,  8.5762e-01]],\n",
       "\n",
       "        [[-7.4332e-02,  6.2600e-01],\n",
       "         [-1.8543e-01,  1.9081e-01],\n",
       "         [ 1.5609e-01,  2.5466e-01],\n",
       "         [-2.7683e-01,  8.0717e-01],\n",
       "         [-1.5093e-01,  6.5516e-01]],\n",
       "\n",
       "        [[ 2.2171e-02, -3.0512e-01],\n",
       "         [ 2.3082e-02,  9.8130e-03],\n",
       "         [ 3.0034e-01, -9.8903e-01],\n",
       "         [ 1.3126e-01, -1.6914e-01],\n",
       "         [-6.0050e-01,  1.0021e+00]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0208],\n",
       "         [-0.0564],\n",
       "         [ 0.0120],\n",
       "         [-0.0282],\n",
       "         [ 0.0148],\n",
       "         [-0.0257],\n",
       "         [-0.0547],\n",
       "         [-0.0626],\n",
       "         [-0.0515],\n",
       "         [-0.0968]], grad_fn=<AddmmBackward>),\n",
       " Normal(loc: torch.Size([10]), scale: torch.Size([10])),\n",
       " Normal(loc: torch.Size([10]), scale: torch.Size([10])))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_policy.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7986, -2.2951],\n",
       "        [-1.7868, -2.3035],\n",
       "        [-1.7848, -2.3046],\n",
       "        [-1.8176, -2.3641],\n",
       "        [-1.7871, -2.2997],\n",
       "        [-1.8295, -2.3181],\n",
       "        [-1.7942, -2.3437],\n",
       "        [-1.7889, -2.2888],\n",
       "        [-1.7894, -2.3200],\n",
       "        [-1.8028, -2.3087]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_policy.model.dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/louis/anaconda3/envs/zarr/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m(1112)\u001b[0;36mconvolve\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1110 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a cannot be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1111 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1112 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v cannot be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1113 \u001b[0;31m    \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1114 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> a\n",
      "a = array([0.5, 0.5])\n",
      "v = array([], dtype=float64)\n",
      "mode = 'valid'\n",
      "ipdb> type(a=\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "ipdb> type(a)\n",
      "<class 'numpy.ndarray'>\n",
      "ipdb> print(a)\n",
      "[0.5 0.5]\n",
      "ipdb> a\n",
      "a = array([0.5, 0.5])\n",
      "v = array([], dtype=float64)\n",
      "mode = 'valid'\n",
      "ipdb> v\n",
      "array([], dtype=float64)\n",
      "ipdb> up\n",
      "> \u001b[0;32m<ipython-input-2-e5dcaac85896>\u001b[0m(27)\u001b[0;36mplot_results\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     25 \u001b[0;31m        \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reward avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m            \u001b[0mrew_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m            \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrew_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'worker {i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.reward_log[i]\n",
      "[]\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 10)\n",
    "a.requires_grad  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = clipped_exp.apply(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from crowd_sim.envs.utils.action import ActionRot\n",
    "from env_setup import *\n",
    "from crowd_sim_ppo import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, Module\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.optim import Adam\n",
    "import math \n",
    "import random\n",
    "from torch.nn.functional import mse_loss\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "from torch.distributions import Categorical\n",
    "from multiprocessing_env import SubprocVecEnv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_policy = gen_policy()\n",
    "env = gen_env(ac_policy)\n",
    "ob = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<crowd_sim.envs.utils.human.Human at 0x7fe026e38550>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = ac_policy.predict(np.asarray([ob]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0142]], grad_fn=<AddmmBackward>),\n",
       " Normal(loc: tensor([-0.0063], grad_fn=<SelectBackward>), scale: tensor([1.0192], grad_fn=<SelectBackward>)),\n",
       " Normal(loc: tensor([0.1188], grad_fn=<SelectBackward>), scale: tensor([1.0146], grad_fn=<SelectBackward>)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  1.0000,  0.0000,  0.3000,  0.0000,  0.0000,  4.2722,\n",
       "          -3.9402,  0.0000,  0.0000,  0.3000,  5.8117,  0.6000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.humans[1].py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Categorical(torch.tensor([1.0,2.9, 3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8668, -0.8668],\n",
       "        [-0.8329, -0.8668]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.log_prob(torch.tensor([[1, 1], [2, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
